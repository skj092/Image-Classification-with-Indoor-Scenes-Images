{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sonujha090/image-classification-indoor-scence?scriptVersionId=110406456\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# importing necessary libraries\nimport os \nfrom pathlib import Path\nfrom glob import glob\nimport random\n\n# Path to the dataset\npath = Path('../input/indoor-scenes-cvpr-2019')\nimage_path = path/'indoorCVPR_09/Images' # Path to the images\nimage_files = glob(str(image_path/'**/*.jpg')) # List of all the images\n\n# shuffle images\nrandom.shuffle(image_files)\n\n# label encoding for the classes\nclass_names = [p.name for p in image_path.glob('*') if p.is_dir()]\n\nlabel2index = {v:k for k,v in enumerate(class_names)}\nindex2label = {v:k for k,v in label2index.items()}\n\n# Creating a dataframe with the image path and the corresponding label\nimport pandas as pd\ndf = pd.DataFrame({'image':image_files})\ndf['label'] = df['image'].map(lambda x: label2index[x.split('/')[-2]])\n\n# Splitting the dataset into train and test\nfrom sklearn.model_selection import train_test_split\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n\n# Saving the train and test dataframe\ntrain_df.to_csv('/train.csv', index=False)\ntest_df.to_csv('/test.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-08T05:24:27.160756Z","iopub.execute_input":"2022-11-08T05:24:27.161683Z","iopub.status.idle":"2022-11-08T05:24:31.571408Z","shell.execute_reply.started":"2022-11-08T05:24:27.161563Z","shell.execute_reply":"2022-11-08T05:24:31.570306Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms\nimport torch \n\nclass config:\n    EPOCHS = 10\n    BATCH_SIZE = 32\n    LEARNING_RATE = 0.001\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    LOAD_MODEL = False\n    SAVE_MODEL = True\n    CHECKPOINT_FILE = \"my_checkpoint.pth.tar\"\n\n    tfms = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor()\n    ])\n\n    # save checkpoint\n    def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n        print(\"=> Saving checkpoint\")\n        torch.save(state, filename)\n\n    # load checkpoint\n    def load_checkpoint(checkpoint, model):\n        print(\"=> Loading checkpoint\")\n        model.load_state_dict(checkpoint['state_dict'])\n\n    # Learning rate scheduler\n    def lr_scheduler(optimizer, epoch, init_lr=0.001, lr_decay_epoch=5):\n        \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n        lr = init_lr * (0.1**(epoch // lr_decay_epoch))\n        if epoch % lr_decay_epoch == 0:\n            print('LR is set to {}'.format(lr))\n\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = lr\n\n        return optimizer  ","metadata":{"execution":{"iopub.status.busy":"2022-11-08T07:09:43.664868Z","iopub.status.idle":"2022-11-08T07:09:43.665646Z","shell.execute_reply.started":"2022-11-08T07:09:43.665369Z","shell.execute_reply":"2022-11-08T07:09:43.665396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader, Subset \nimport pandas as pd \nimport torch, torchvision\nfrom PIL import Image \nfrom torchvision import transforms \n\nclass IndoorSceneDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = Image.open(row['image']).convert('RGB')\n        if self.transform:\n            img = self.transform(img)\n        return img, row['label']\n\nif __name__=='__main__':\n    df = pd.read_csv('/train.csv')\n    ds = IndoorSceneDataset(df, transform=tfms)\n    dl = DataLoader(ds, batch_size=32, shuffle=True)\n    for xb, yb in dl:\n        print(xb.shape, yb.shape)\n        break","metadata":{"execution":{"iopub.status.busy":"2022-11-08T05:47:04.73188Z","iopub.execute_input":"2022-11-08T05:47:04.732605Z","iopub.status.idle":"2022-11-08T05:47:05.592599Z","shell.execute_reply.started":"2022-11-08T05:47:04.732568Z","shell.execute_reply":"2022-11-08T05:47:05.591383Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"torch.Size([32, 3, 224, 224]) torch.Size([32])\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm\nimport numpy as np \nimport torch\nfrom sklearn.metrics import accuracy_score\n\ndef train_model(model, train_dl, valid_dl, optimizer, criterion, num_epochs=10, device=device):\n    train_losses, valid_losses, train_acc, valid_acc = [], [], [], []\n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0\n        train_correct = 0\n        for x, y in tqdm(train_dl):\n            optimizer.zero_grad()\n            x, y = x.to(device), y.to(device)\n            y_pred = model(x)\n            loss = criterion(y_pred, y)\n            loss.backward()\n            optimizer.step()\n            train_losses.append(loss.item())\n            accuracy = accuracy_score(y.detach().cpu().numpy(), y_pred.argmax(dim=1).detach().cpu().numpy())\n            train_acc.append(accuracy)\n        model.eval()\n        for x, y in tqdm(valid_dl):\n            x, y = x.to(device), y.to(device)\n            y_pred = model(x)\n            loss = criterion(y_pred, y)\n            accuracy = accuracy_score(y.detach().cpu().numpy(), y_pred.argmax(dim=1).detach().cpu().numpy())\n            valid_losses.append(loss.item())\n            valid_acc.append(accuracy)\n        print(f'Epoch: {epoch+1}, Train Loss: {np.mean(train_losses):.4f}, Train Accuracy: {np.mean(train_acc):.4f}, Valid Loss: {np.mean(valid_losses):.4f}, Valid Accuracy: {np.mean(valid_acc):.4f}')","metadata":{"execution":{"iopub.status.busy":"2022-11-08T05:47:06.00969Z","iopub.execute_input":"2022-11-08T05:47:06.010348Z","iopub.status.idle":"2022-11-08T05:47:06.021722Z","shell.execute_reply.started":"2022-11-08T05:47:06.010301Z","shell.execute_reply":"2022-11-08T05:47:06.020628Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"%%time \n\nimport torch, torchvision\nfrom torch.utils.data import Dataset, DataLoader, Subset \n# from dataset import IndoorSceneDataset, tfms\nimport pandas as pd\nimport sys \n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nbs = 32\n\ntrain_df = pd.read_csv('/train.csv')\nvalid_df = pd.read_csv('/test.csv')\n\ntrain_dataset = IndoorSceneDataset(train_df, transform=tfms)\nvalid_dataset = IndoorSceneDataset(valid_df, transform=tfms)\n\ntrain_dataset = Subset(train_dataset, range(0, int(len(train_dataset)*0.1)))\nvalid_dataset = Subset(train_dataset, range(0, int(len(valid_dataset)*0.1)))\n\ntrain_dl = DataLoader(train_dataset, batch_size=32, shuffle=True)\nvalid_dl = DataLoader(valid_dataset, batch_size=32, shuffle=True)\n\n\nmodel = torchvision.models.resnet18(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad = False\nmodel.fc = torch.nn.Linear(512, 67)\n\n# load checkpoint\nif config.LOAD_MODEL and config.CHECKPOINT_FILE in os.listdir():\n    load_checkpoint(torch.load(config.CHECKPOINT_FILE), model)\n\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nmodel = model.to(device) \n\ntrain_model(model, train_dl, valid_dl, optimizer, criterion, num_epochs=5)\n\n# save checkpoint\nif config.SAVE_MODEL:\n    checkpoint = {\n        'state_dict': model.state_dict(),\n        'optimizer': optimizer.state_dict()\n    }\n    save_checkpoint(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T07:10:18.513286Z","iopub.execute_input":"2022-11-08T07:10:18.513637Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"=> Loading checkpoint\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 32/40 [00:12<00:03,  2.02it/s]","output_type":"stream"}]},{"cell_type":"code","source":"# # load checkpoint\n# if config.LOAD_MODEL and config.CHECKPOINT_FILE in os.listdir():\n#     load_checkpoint(torch.load(config.CHECKPOINT_FILE), model)\n\n# model = model.to(device) \n\n# train_model(model, train_dl, valid_dl, optimizer, criterion, num_epochs=5)\n\n# # save checkpoint\n# if config.SAVE_MODEL:\n#     checkpoint = {\n#         'state_dict': model.state_dict(),\n#         'optimizer': optimizer.state_dict()\n#     }\n#     save_checkpoint(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T07:10:00.246823Z","iopub.execute_input":"2022-11-08T07:10:00.247198Z","iopub.status.idle":"2022-11-08T07:10:10.845619Z","shell.execute_reply.started":"2022-11-08T07:10:00.247147Z","shell.execute_reply":"2022-11-08T07:10:10.843231Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"=> Loading checkpoint\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▌   | 26/40 [00:10<00:05,  2.48it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3723259417.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# save checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/3126276805.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dl, valid_dl, optimizer, criterion, num_epochs, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}